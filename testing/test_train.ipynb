{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDL Model Training Test Notebook\n",
    "# Install dependencies if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "install_if_missing(\"torch\")\n",
    "install_if_missing(\"opencv-python\")\n",
    "install_if_missing(\"pyyaml\")\n",
    "\n",
    "print(\"Dependencies installed successfully!\")\n",
    "print(\"PyTorch version:\", __import__(\"torch\").__version__)\n",
    "print(\"OpenCV version:\", __import__(\"cv2\").__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39961205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EDL modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path to import EDL\n",
    "sys.path.append(str(Path('..').absolute()))\n",
    "\n",
    "# Import EDL components\n",
    "from EDL.model import MiniYOLO\n",
    "from EDL.data import YOLOTxtDataset, collate_fn\n",
    "from EDL.engine import train_loop, assign_targets, compute_loss, decode_predictions\n",
    "from EDL.utils import seed_everything, parse_device, make_dir, now_str\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "print(\"EDL modules imported successfully!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset for testing\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Create test dataset directory structure\n",
    "make_dir(\"test_dataset/images/train\")\n",
    "make_dir(\"test_dataset/images/val\")\n",
    "make_dir(\"test_dataset/labels/train\")\n",
    "make_dir(\"test_dataset/labels/val\")\n",
    "\n",
    "# Generate sample images and labels\n",
    "def create_sample_data(split, num_samples=10):\n",
    "    for i in range(num_samples):\n",
    "        # Create random 640x640 RGB image\n",
    "        img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
    "        img_path = f\"test_dataset/images/{split}/sample_{i:03d}.jpg\"\n",
    "        cv2.imwrite(img_path, img)\n",
    "        \n",
    "        # Create random YOLO format labels (class cx cy w h normalized)\n",
    "        num_objects = random.randint(1, 5)\n",
    "        labels = []\n",
    "        for _ in range(num_objects):\n",
    "            cls = 0  # single class for testing\n",
    "            cx = random.uniform(0.1, 0.9)\n",
    "            cy = random.uniform(0.1, 0.9)\n",
    "            w = random.uniform(0.05, 0.3)\n",
    "            h = random.uniform(0.05, 0.3)\n",
    "            labels.append(f\"{cls} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")\n",
    "        \n",
    "        # Save label file\n",
    "        label_path = f\"test_dataset/labels/{split}/sample_{i:03d}.txt\"\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write('\\n'.join(labels))\n",
    "\n",
    "# Generate train and val samples\n",
    "create_sample_data(\"train\", 20)\n",
    "create_sample_data(\"val\", 10)\n",
    "\n",
    "print(\"Sample dataset created!\")\n",
    "print(\"Train images:\", len(list(Path(\"test_dataset/images/train\").glob(\"*.jpg\"))))\n",
    "print(\"Val images:\", len(list(Path(\"test_dataset/images/val\").glob(\"*.jpg\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset YAML configuration\n",
    "dataset_config = {\n",
    "    'path': str(Path('test_dataset').absolute()),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'names': ['person']  # single class for testing\n",
    "}\n",
    "\n",
    "# Save dataset YAML\n",
    "with open('test_data.yaml', 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Dataset YAML created:\")\n",
    "print(yaml.dump(dataset_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a37e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset loading\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load dataset\n",
    "train_ds = YOLOTxtDataset('test_data.yaml', split='train', img_size=640)\n",
    "val_ds = YOLOTxtDataset('test_data.yaml', split='val', img_size=640)\n",
    "\n",
    "print(f\"Train dataset: {len(train_ds)} samples\")\n",
    "print(f\"Val dataset: {len(val_ds)} samples\")\n",
    "print(f\"Number of classes: {train_ds.num_classes}\")\n",
    "print(f\"Class names: {train_ds.names}\")\n",
    "\n",
    "# Test data loading\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "sample_batch = next(iter(train_dl))\n",
    "\n",
    "print(f\"\\nSample batch:\")\n",
    "print(f\"Images shape: {sample_batch['images'].shape}\")\n",
    "print(f\"Number of label tensors: {len(sample_batch['labels'])}\")\n",
    "print(f\"First image labels shape: {sample_batch['labels'][0].shape}\")\n",
    "print(f\"Paths: {len(sample_batch['paths'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model initialization and forward pass\n",
    "device = parse_device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = MiniYOLO(num_classes=1, channels=128).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "imgs = sample_batch['images'].to(device)\n",
    "print(f\"Input shape: {imgs.shape}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(imgs)\n",
    "    print(f\"Output shape: {pred.shape}\")\n",
    "    print(f\"Model stride: {model.stride}\")\n",
    "\n",
    "# Verify output channels\n",
    "expected_channels = 1 + model.num_classes + 4  # obj + classes + box\n",
    "print(f\"Expected output channels: {expected_channels}\")\n",
    "print(f\"Actual output channels: {pred.shape[1]}\")\n",
    "\n",
    "# Test loss computation\n",
    "labels = [l.to(device) for l in sample_batch['labels']]\n",
    "B, _, H, W = imgs.shape\n",
    "S = H // 16\n",
    "obj_t, cls_t, box_t, mask = assign_targets(labels, S, model.num_classes)\n",
    "obj_t, cls_t, box_t, mask = obj_t.to(device), cls_t.to(device), box_t.to(device), mask.to(device)\n",
    "\n",
    "loss, logs = compute_loss(pred, obj_t, cls_t, box_t, mask, model.num_classes)\n",
    "print(f\"\\nLoss test:\")\n",
    "print(f\"Total loss: {logs['loss']:.4f}\")\n",
    "print(f\"Obj loss: {logs['obj_loss']:.4f}\")\n",
    "print(f\"Cls loss: {logs['cls_loss']:.4f}\")\n",
    "print(f\"Box loss: {logs['box_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training test (few epochs)\n",
    "import time\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# Training setup\n",
    "model = MiniYOLO(num_classes=1).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "# Create output directory\n",
    "make_dir(\"runs/test_train\")\n",
    "\n",
    "# Quick training loop\n",
    "model.train()\n",
    "num_epochs = 3\n",
    "print(f\"Starting quick training for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dl):\n",
    "        imgs = batch['images'].to(device)\n",
    "        labels = [l.to(device) for l in batch['labels']]\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(imgs)\n",
    "        \n",
    "        # Compute targets and loss\n",
    "        B, _, H, W = imgs.shape\n",
    "        S = H // 16\n",
    "        obj_t, cls_t, box_t, mask = assign_targets(labels, S, model.num_classes)\n",
    "        obj_t, cls_t, box_t, mask = obj_t.to(device), cls_t.to(device), box_t.to(device), mask.to(device)\n",
    "        \n",
    "        loss, logs = compute_loss(pred, obj_t, cls_t, box_t, mask, model.num_classes)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += logs['loss']\n",
    "        num_batches += 1\n",
    "        \n",
    "        if batch_idx % 2 == 0:  # Log every 2 batches\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}, Loss: {logs['loss']:.4f}\")\n",
    "    \n",
    "    avg_loss = epoch_loss / max(1, num_batches)\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1} completed: avg_loss={avg_loss:.4f}, time={epoch_time:.1f}s\")\n",
    "\n",
    "# Save test model\n",
    "test_weights_path = \"runs/test_train/test_model.pt\"\n",
    "meta = {\n",
    "    'imgsz': 640,\n",
    "    'stride': 16,\n",
    "    'names': ['person'],\n",
    "    'num_classes': 1,\n",
    "}\n",
    "torch.save({'model': model.state_dict(), 'meta': meta}, test_weights_path)\n",
    "print(f\"Test model saved to: {test_weights_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test full training using EDL train script\n",
    "# Create an args-like object for the training function\n",
    "class TrainingArgs:\n",
    "    def __init__(self):\n",
    "        self.data = 'test_data.yaml'\n",
    "        self.epochs = 5\n",
    "        self.batch = 4\n",
    "        self.imgsz = 640\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.lr = 1e-3\n",
    "        self.workers = 0  # Set to 0 for notebook to avoid multiprocessing issues\n",
    "        self.out = 'runs/test_full_train'\n",
    "        self.seed = 42\n",
    "        self.num_classes = None  # Will use from dataset\n",
    "        self.log_interval = 2\n",
    "\n",
    "# Test using the actual train_loop function\n",
    "print(\"Testing full training pipeline...\")\n",
    "args = TrainingArgs()\n",
    "\n",
    "# Run training\n",
    "try:\n",
    "    train_loop(args)\n",
    "    print(\"✅ Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
